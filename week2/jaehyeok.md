# 에이전틱 아키텍처 정리

본 문서는 반응형(Reactive), 계획 기반형(Planning-based), 하이브리드(Hybrid), 룰베이스 자동화(Rule-based Automation) 아키텍처를 명확히 구분하고, 각각의 구조적 차이와 장단점을 한눈에 정리한 내용이다.

---

## 1. 반응형 아키텍처 (Reactive Architecture)

### 정의
반응형 아키텍처는 명시적 계획(Plan)이 없고, 매 순간 Observation을 기반으로 Policy가 Action을 선택한다. 즉, 행동 선택이 실시간으로 이루어진다.

### 특징
- Plan 없음
- Observation → Policy → Action 구조
- 상황 변화에 즉각 반응
- 행동 선택권이 Policy에 있음

### 반응형 vs 룰베이스 자동화 비교

반응형 아키텍처는 상태(Observation)를 기반으로 정책(Policy)이 행동을 선택하지만, 룰베이스 자동화는 사람이 작성한 고정된 규칙(if-then-else)에 의존한다.

- 반응형: Observation → Policy → Action 구조로, 실행 시점에 행동을 새로 선택할 수 있다.
- 룰베이스: 조건이 일치하면 미리 정의된 액션만 수행하며, 새로운 상황이나 입력 변화에 대응하기 어렵다.
- 반응형은 학습 기반 정책을 활용해 일반화가 가능하지만, 룰베이스는 규칙 추가·변경 없이는 새로운 상황을 처리할 수 없다.


요약하면, 반응형은 동적인 정책 기반 의사결정을 수행하고, 룰베이스는 정적인 규칙 실행에 머무른다는 점에서 본질적으로 다르다.

### 장점
- **실행 유연성**  
  - 실행 시점마다 Observation을 기반으로 행동을 다시 선택한다.  
  - 계획 기반형처럼 계획 시점의 정보에 묶이지 않아 변화 대응이 즉각적이다.

- **상황 적응력**  
  - 환경 변화가 발생해도 재계획 과정이 필요 없다.  
  - 매 스텝 Observation을 활용해 즉시 행동을 갱신하므로 실시간 적응에 강하다.

- **예외 대응력**  
  - 사전에 예측하지 않은 입력·패턴·상황도 정책(Policy)의 일반화 능력으로 처리 가능하다.  
  - 계획 기반형처럼 “계획에 존재하는 예외만 처리 가능”한 제약이 없다.

### 한계
- **장기 목표 부재**  
  - 자체적으로 작업 순서를 구성하지 못하며 구조화된 멀티스텝 태스크에 취약하다.

- **전체 플로우 관리 한계**  
  - Plan이 없기 때문에 작업 맥락 유지나 큰 목표 달성이 어렵다.

- **정책 의존도**  
  - 행동 품질이 Policy(모델)의 성능에 강하게 의존하며, 잘못 학습된 정책은 잘못된 행동을 반복할 수 있다.

---

## 2. 계획 기반형 아키텍처 (Planning-based Architecture)

### 정의
Planner가 전체 작업의 스텝을 포함한 Plan을 생성하고, Executor는 이 Plan을 그대로 수행한다. 행동(action)의 원천이 Plan이다.

### 특징
- 명시적 Plan 존재
- Plan이 전체 sequence를 지배
- Executor는 판단하지 않고 계획을 수행
- 환경 변화 시 재계획(Re-plan)이 필요

### 장점
- 장기 목표를 가진 멀티스텝 작업에 적합하다.
- 전체 플로우가 명확해 관리와 검증이 쉽다.
- 반복적이고 구조화된 작업에서 높은 안정성을 보인다.

### 한계
- 실행 시점에 행동을 바꾸기 어렵다.
- 환경 변화나 예외에 대응하려면 재계획(Re-plan)이 필요해 비용이 크다.
- 계획 수립 시점의 정보에 의존하기 때문에 실제 상황과 어긋나기 쉽다.

---

## 3. 하이브리드 아키텍처 (Hybrid Architecture)

### 정의
Plan과 Policy가 함께 의사결정에 관여하는 구조다. 고레벨 의사결정은 Plan이 담당하고, 저레벨 행동 선택은 Policy가 담당한다.

### 특징
- Plan으로 전체 방향 제공
- 세부 action은 Policy가 상황 기반으로 선택
- 실행 과정에서 반응형 특성을 활용해 예외 대응 가능

### 예시
Plan: OCR → 날짜 추출 → 정규화 → DB 업데이트  
Policy: OCR 실패 시 모델 교체, 날짜 다중 추출 시 신뢰도 기반 선택 등

### 장점
- 계획 기반형의 장기 구조와 반응형의 실시간 적응성을 동시에 제공한다.
- 실행 중 발생하는 예외를 반응형 레이어가 처리해 안정성이 높다.
- 다양한 입력·환경 변화에서도 전체 목표를 유지하며 유연하게 대응할 수 있다.

### 한계
- 구조가 복잡해 설계와 구현 비용이 높다.
- Plan과 Policy 간 충돌 가능성이 있어 조정 로직이 필요하다.
- 디버깅 난이도가 증가한다.

---

## 전체 비교 요약

| 구조 | Plan | Action 선택 주체 | 유연성 | 적응력 | 예외 대응 | 특징 |
|------|------|------------------|--------|--------|------------|--------|
| 반응형 | 없음 | Policy | 높음 | 높음 | 강함 | 실시간 판단 기반 |
| 계획 기반형 | 있음 | Plan | 낮음 | 낮음 | 약함 | Plan 중심의 멀티스텝 작업 |
| 하이브리드 | 있음 | Plan + Policy | 중간~높음 | 높음 | 강함 | 이중 의사결정 구조 |

---

## 결론

- 반응형은 실행이 유연하고 상황 적응력이 뛰어나며 예외 대응 능력이 강하다.  
- 계획 기반형은 Plan이 전체를 지배하며 멀티스텝 작업에 적합하다.  
- 하이브리드는 두 방식의 장점을 결합해 복잡한 실무 태스크에 적합하다.  
- 룰베이스 자동화는 예측 가능한 고정 패턴에만 적합하다.

---

## 4. MAS(Multi-Agent System) 관점에서의 위치 정리

### 4.1 MAS(Multi-Agent System) 전체 구조

여기서 말하는 MAS는 “여러 개의 에이전트가 같은 환경에서 상호작용하며 하나의 시스템을 이루는 구조”를 말한다.  
즉, MAS는 개별 에이전트가 아니라 **시스템 전체의 구성 방식**을 다룬다.

- 관점
  - “에이전트들이 어떤 토폴로지(중앙집중형 / 분산형 / 계층형)로 묶여 있는가?”
  - “어떤 프로토콜로 협상·협력·경쟁하는가?”
  - “전체 목표를 어떻게 나누어 개별 에이전트에게 배분하는가?”

정리하면, MAS는 **여러 에이전트가 어떻게 연결되고, 어떻게 같이 일하는지**에 대한 시스템 레벨의 이야기다.

### 4.2 Agent 내부 아키텍처(계획형/반응형)의 위치

반대로, 계획 기반형 / 반응형 / 하이브리드 / 룰베이스 등은  
“**각각의 Agent 내부에서 의사결정을 어떻게 설계할 것인가**”에 대한 아키텍처이다.

- MAS: 다수의 에이전트가 서로 어떻게 얽혀 있는가(시스템 레벨)
- Agent Architecture: 한 에이전트 안에서 Observation → Decision → Action이 어떻게 구현되는가(로컬 레벨)


따라서 일반적으로 “에이전틱 시스템 아키텍처에서 계획형 vs 반응형”을 이야기할 때는  
MAS 전체 구조가 아니라, “**각 에이전트의 내부 논리 구조**”를 가리키는 경우가 대부분이다.

---

## 5. MAS(Multi-Agent System)에서의 협상(Negotiation)

본 절에서는 앞서 정리한 1) 반응형, 2) 계획 기반형, 3) 하이브리드, 4) MAS 구조 관점 위에,  
**e커머스 도메인에서 실제로 나타나는 협상(Negotiation)의 의미와 구조**를 정리한다.

### 5.1 협상의 정의

MAS에서의 협상은 사람이 말하는 감정적·대화적 협상이 아니라,  
**여러 에이전트가 서로 다른 목표를 가지고 제한된 자원을 공유할 때 발생하는 자동화된 조정·합의 절차**를 의미한다.

즉, 협상은 “갈등을 최소화하고 전체 시스템 효율을 유지하기 위한 조정 프로토콜”이다.

---

### 5.2 협상이 필요한 이유 (1~4번 구조와의 연결)

- **(1) 반응형 에이전트**는 환경 기반 행동 선택을 실시간으로 한다.  
  → 여러 에이전트가 동시에 반응하면 행동 충돌이 쉽게 발생한다.  
  → 충돌 완화를 위해 협상 또는 조정 규칙이 필요하다.

- **(2) 계획 기반형 에이전트**는 자체 Plan을 실행한다.  
  → 여러 에이전트의 Plan이 동일 자원(슬롯·재고·비용)을 쓰면 충돌이 발생한다.  
  → 이때 Plan 간 충돌을 조정하는 과정이 협상이다.

- **(3) 하이브리드 에이전트**는 Plan + Policy가 함께 동작한다.  
  → Plan 레벨에서는 장기 구조가 충돌할 수 있고,  
    Policy 레벨에서는 실시간 행동이 충돌할 수 있다.  
  → 두 레벨 모두에서 협상 메커니즘이 필요해진다.

- **(4) MAS 전체 구조**는 여러 에이전트가 하나의 환경을 공유한다.  
  → 환경·자원·슬롯·우선순위가 공유되기 때문에 갈등이 필연적으로 생기고,  
    이를 해결하는 핵심 기술이 협상이다.

---

### 5.3 e커머스 시나리오 기반 협상 유형

아래 예시는 실제 e커머스 도메인에 존재하는 MAS 기반 협상의 대표적인 형태다.

#### 5.3.1 자원(Resource) 충돌 협상  
- 쿠폰 추천 Agent: “이 SKU는 할인을 강하게 걸면 전환 상승 가능.”  
- 재고 Agent: “재고 위험 있음. 과한 노출은 불가.”

**협상 결과 예**  
- “쿠폰 발송 대상을 30% 축소하는 조건으로 발송 승인.”  
→ 이는 제한된 재고라는 자원 위에서 목표가 충돌할 때 이루어지는 전형적인 negotiation.

---

#### 5.3.2 노출 슬롯(Slot) 배분 협상  
메인·카테고리·기획전 등 노출 슬롯은 항상 부족하다.

- CRM Agent: 개인화 쿠폰 노출이 uplift에 중요  
- 기획전 Agent: 시즌성 기획전이 상단 배너를 필요  
- 추천 Agent: 개인화 추천 영역 필요

**협상 결과 예**  
- 우선순위 스코어 기반 자동 배분  
- 또는 bid → counter-bid → 결정 형태의 메시지 기반 협상 구조

---

#### 5.3.3 Task Allocation 협상  
물류센터 내 작업 요청이 서로 경쟁:

- Inbound Agent: 입고 처리 우선  
- Outbound Agent: 당일배송 마감 시한  
- 반품 Agent: 처리 SLA 준수 필요

**협상 결과 예**  
- 전체 효용(utility)을 계산해 작업자·로봇·시간 슬롯을 자동 분배  
- Time-window 기반으로 양보/우선권 조정

---

#### 5.3.4 모델 기반 의사결정 충돌 협상  
추천 시스템 내부에서도 협상이 발생:

- Retriever A: 고객 기반 추천 주장  
- Retriever B: 콘텐츠 기반 추천 주장  
- Retriever C: 탐색(exploration) 강조  
- Reranker Agent: 이들 후보군을 조합해 최종 결정

**협상 구조 예**  
- 각 Retriever가 점수 또는 confidence를 bid 형태로 제시  
- Reranker가 합의된 top-k 후보군을 선택 → 사실상 협상 중재자 역할

---

### 5.4 협상 프로토콜(Protocol)의 구조적 형태

협상은 크게 다음과 같은 프로토콜로 구현된다.

- **Auction-based Negotiation**  
  - 에이전트가 자원을 얻기 위해 bid를 제출  
  - 최적 bid를 기반으로 자동 결정  
- **Contract Net Protocol(CNP)**  
  - Manager-Agent가 작업을 ‘입찰 공고’  
  - 참여 에이전트가 bid  
  - 가장 적합한 Agent에게 작업 배정  
- **Mediator-based Negotiation**  
  - 중재자 에이전트가 다수의 요청을 받아 conflict를 해결  
- **Rule-based Negotiation**  
  - 미리 정의된 우선순위, 제한 조건 기반 자동 

---
## 6. 지식베이스(Knowledge Base)와 지식 업데이트 정리

본 절에서는 에이전트 이론(AGM Belief Revision, BDI 모델)과 현대 LLM 기반 Agent 구조(RAG, Vector KB)의 관점에서  
지식베이스(KB)와 지식 업데이트 프로세스를 통합적으로 정리한다.

### 6.1 KB(Knowledge Base)의 정의

지식베이스(KB)는 단순한 데이터 저장소(DB)가 아니라,  
**에이전트가 추론·판단·결정을 수행하기 위해 참조하는 ‘지식’의 저장소**이다.

- DB(Database): 원본 데이터 저장  
- KB(Knowledge Base): 규칙, 사실, 정책, 의미적 정보 등 ‘의사결정에 필요한 지식’ 저장

즉, KB는 에이전트의 “머릿속에 들어있는 지적 자산”에 해당한다.

### 6.2 KB의 두 가지 형태

1) **Symbolic Knowledge Base**  
   - 논리 기반 Fact, Rule, Ontology, Graph  
   - 예:  
     - `StockRisk(x) :- stock(x) < 10`  
     - `Category(apple, fruit)`

2) **Vector Knowledge Base (RAG에서 사용)**  
   - 텍스트 chunk + embedding + metadata  
   - 의미 기반 검색 및 추론에 활용  

### 6.4 LLM Agent에서의 지식 업데이트(현대 구현 방식)

현대 환경에서는 전통 이론을 실제 파이프라인으로 변환해 아래 3단계 체인으로 구성한다.


#### (1) Knowledge Filtering (지식 가치 판단)
새로운 정보가 미래 추론에 가치 있는지 여부를 판단한다.  
단순 Q/A는 저장하지 않고,  
정책, 규칙, 운영 기준, 도메인 사실 등 의미 있는 정보만 채택한다.

#### (2) Knowledge Canonicalization (지식 형태로 변환)
추론 가능한 지식 형태로 변환한다.
- 요약
- 정규화
- 구조화(JSON 등)
- Embedding 생성
- Metadata 생성

#### (3) Knowledge Storage (KB에 저장)
Symbolic KB 또는 Vector KB(RAG) 형태로 저장한다.  
이후 Retrieval을 통해 추론에 사용된다.

### 6.5 Q/A 저장과 KB 업데이트의 차이

- Q/A 그대로 저장 → **Memory(메모리)**  
- Q/A에서 의미 있는 지식을 추출해 저장 → **KB 업데이트**

즉, KB는 “재사용 가치가 있는 지식만 저장하는 구조”이다.

### 6.6 MAS 내 지식 업데이트의 역할

멀티에이전트 환경에서는 다음 개념으로 지식이 관리된다.

- **Local Knowledge**: 개별 Agent의 Belief  
- **Shared Knowledge**: 필요 시 Agent 간 공유되는 지식  
- **Common Knowledge**: 협상·조정에 반드시 필요한 공통 지식  

각 Agent는 Observation을 기반으로 자신의 Belief를 업데이트하고,  
필요하면 다른 Agent와 정보를 공유해 전체 시스템의 일관성을 유지한다.
